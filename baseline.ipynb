{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "b2b4f5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import data_utils as du\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from utils.data import load_PPMI_data\n",
    "\n",
    "data_dir = du.find_data_dir('app')\n",
    "dataloader_file = du.get_file_path(data_dir, 'class based structure', 'dataloaders', 'dataloader.p')\n",
    "dataloader = du.read_from_pickle(dataloader_file)\n",
    "adjlists, edge_metapath_indices_list, features_list, adjM, type_mask, labels, train_val_test_idx = load_PPMI_data()\n",
    "\n",
    "train_idx = train_val_test_idx['train_idx']\n",
    "train_idx = np.sort(train_idx)\n",
    "test_idx = train_val_test_idx['test_idx']\n",
    "test_idx = np.sort(test_idx)\n",
    "val_idx = train_val_test_idx['val_idx']\n",
    "val_idx = np.sort(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ac5146f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_df4d3_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Amount</th>        <th class=\"col_heading level0 col1\" >Percentage</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_df4d3_level0_row0\" class=\"row_heading level0 row0\" >-1</th>\n",
       "                        <td id=\"T_df4d3_row0_col0\" class=\"data row0 col0\" >91</td>\n",
       "                        <td id=\"T_df4d3_row0_col1\" class=\"data row0 col1\" >39.9%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4d3_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
       "                        <td id=\"T_df4d3_row1_col0\" class=\"data row1 col0\" >70</td>\n",
       "                        <td id=\"T_df4d3_row1_col1\" class=\"data row1 col1\" >30.7%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4d3_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "                        <td id=\"T_df4d3_row2_col0\" class=\"data row2 col0\" >67</td>\n",
       "                        <td id=\"T_df4d3_row2_col1\" class=\"data row2 col1\" >29.4%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_df4d3_level0_row3\" class=\"row_heading level0 row3\" >Total</th>\n",
       "                        <td id=\"T_df4d3_row3_col0\" class=\"data row3 col0\" >228</td>\n",
       "                        <td id=\"T_df4d3_row3_col1\" class=\"data row3 col1\" >100.0%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f5b3566b460>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.target_distribution_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fa7388",
   "metadata": {},
   "source": [
    "### Experimentation with ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a73c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.metrics import f1_score, SCORERS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "161bd894",
   "metadata": {},
   "outputs": [],
   "source": [
    "h = .02  # step size in the mesh\n",
    "\n",
    "names = [\"Nearest Neighbors 4\", \"Linear SVM\", \"Linear SVM MAGNN\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(4),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    LinearSVC(dual=False),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=100, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "X, y = dataloader.X.iloc[test_idx].values, np.array(dataloader.y.iloc[test_idx]).astype(int)\n",
    "\n",
    "# X = StandardScaler(with_mean=False).fit_transform(X)\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=.5, random_state=43)\n",
    "\n",
    "scores = []\n",
    "\n",
    "# iterate over classifiers\n",
    "# for name, clf in zip(names, classifiers):\n",
    "#     print(name)\n",
    "#     clf.fit(X_train, y_train)\n",
    "#     predicted = clf.predict(X_test)\n",
    "#     f1_macro = f1_score(y_test, predicted, average='macro')\n",
    "#     f1_micro = f1_score(y_test, predicted, average='micro')\n",
    "#     scores.append((name, f1_macro, f1_micro))\n",
    "    \n",
    "# df = pd.DataFrame(scores, columns=['Name', 'f1_macro', 'f1_micro']).set_index('Name', drop=True).style.format({'f1_macro': \"{:.1%}\", 'f1_micro': \"{:.1%}\"})\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "5e3cf533",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_test(X, y, clf, test_sizes=(0.2, 0.4, 0.6, 0.8), repeat=10):\n",
    "    random_states = [182318 + i for i in range(repeat)]\n",
    "    result_macro_f1_list = []\n",
    "    result_micro_f1_list = []\n",
    "    for test_size in test_sizes:\n",
    "        macro_f1_list = []\n",
    "        micro_f1_list = []\n",
    "        for i in range(repeat):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, shuffle=True, random_state=random_states[i])\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "            macro_f1_list.append(macro_f1)\n",
    "            micro_f1_list.append(micro_f1)\n",
    "        result_macro_f1_list.append((np.mean(macro_f1_list), np.std(macro_f1_list)))\n",
    "        result_micro_f1_list.append((np.mean(micro_f1_list), np.std(micro_f1_list)))\n",
    "    return result_macro_f1_list, result_micro_f1_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "a5cb26ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_mean_std(mean_std):\n",
    "    mean, std = mean_std\n",
    "    mean_perc = mean*100\n",
    "    std_perc = std*100\n",
    "    return f'{mean_perc:.1f}%~{std_perc:.1f}%'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "161c6287",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((137, 255), (137,))"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86326e6",
   "metadata": {},
   "source": [
    "### Do correct statistical tests with Baselines for good comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "8035397b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sizes = [0.8, 0.6, 0.4, 0.2]\n",
    "df_tests_macro = pd.DataFrame([], columns=train_sizes)\n",
    "df_tests_micro = pd.DataFrame([], columns=train_sizes)\n",
    "\n",
    "for name, clf in list(zip(names, classifiers)):\n",
    "    result_macro_f1_list, result_micro_f1_list = clf_test(X, y, clf)\n",
    "    df_tests_macro = df_tests_macro.append(pd.Series(result_macro_f1_list, index=train_sizes, name='TEST').apply(format_mean_std), ignore_index=True)\n",
    "    df_tests_micro = df_tests_micro.append(pd.Series(result_micro_f1_list, index=train_sizes, name='TEST').apply(format_mean_std), ignore_index=True)\n",
    "df_tests_macro.index = names\n",
    "df_tests_micro.index = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "d8af0eeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors 4</th>\n",
       "      <td>31.7%~7.5%</td>\n",
       "      <td>31.0%~7.3%</td>\n",
       "      <td>32.2%~4.4%</td>\n",
       "      <td>32.0%~5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>25.8%~8.0%</td>\n",
       "      <td>27.9%~6.3%</td>\n",
       "      <td>30.2%~4.1%</td>\n",
       "      <td>27.4%~3.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM MAGNN</th>\n",
       "      <td>34.2%~5.4%</td>\n",
       "      <td>37.1%~4.9%</td>\n",
       "      <td>36.8%~4.6%</td>\n",
       "      <td>35.0%~3.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>35.4%~9.9%</td>\n",
       "      <td>38.5%~6.3%</td>\n",
       "      <td>35.3%~5.2%</td>\n",
       "      <td>31.8%~4.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>31.6%~9.5%</td>\n",
       "      <td>32.3%~5.5%</td>\n",
       "      <td>32.8%~4.0%</td>\n",
       "      <td>33.2%~4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Net</th>\n",
       "      <td>35.3%~7.8%</td>\n",
       "      <td>29.6%~9.2%</td>\n",
       "      <td>31.8%~9.1%</td>\n",
       "      <td>34.2%~3.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>32.8%~9.0%</td>\n",
       "      <td>32.1%~6.4%</td>\n",
       "      <td>30.0%~3.9%</td>\n",
       "      <td>31.8%~5.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>30.0%~8.0%</td>\n",
       "      <td>32.0%~6.3%</td>\n",
       "      <td>33.2%~2.8%</td>\n",
       "      <td>34.6%~4.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0.8         0.6         0.4         0.2\n",
       "Nearest Neighbors 4  31.7%~7.5%  31.0%~7.3%  32.2%~4.4%  32.0%~5.0%\n",
       "Linear SVM           25.8%~8.0%  27.9%~6.3%  30.2%~4.1%  27.4%~3.4%\n",
       "Linear SVM MAGNN     34.2%~5.4%  37.1%~4.9%  36.8%~4.6%  35.0%~3.0%\n",
       "Decision Tree        35.4%~9.9%  38.5%~6.3%  35.3%~5.2%  31.8%~4.6%\n",
       "Random Forest        31.6%~9.5%  32.3%~5.5%  32.8%~4.0%  33.2%~4.0%\n",
       "Neural Net           35.3%~7.8%  29.6%~9.2%  31.8%~9.1%  34.2%~3.2%\n",
       "AdaBoost             32.8%~9.0%  32.1%~6.4%  30.0%~3.9%  31.8%~5.8%\n",
       "Naive Bayes          30.0%~8.0%  32.0%~6.3%  33.2%~2.8%  34.6%~4.5%"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tests_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "0e006403",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors 4</th>\n",
       "      <td>32.9%~7.1%</td>\n",
       "      <td>32.2%~7.1%</td>\n",
       "      <td>34.1%~4.3%</td>\n",
       "      <td>33.2%~5.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>27.1%~8.2%</td>\n",
       "      <td>30.2%~4.1%</td>\n",
       "      <td>34.5%~4.1%</td>\n",
       "      <td>32.3%~2.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM MAGNN</th>\n",
       "      <td>35.7%~5.1%</td>\n",
       "      <td>37.6%~4.8%</td>\n",
       "      <td>37.3%~4.4%</td>\n",
       "      <td>35.6%~3.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>37.1%~9.1%</td>\n",
       "      <td>39.5%~6.1%</td>\n",
       "      <td>36.4%~4.8%</td>\n",
       "      <td>33.5%~3.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>32.9%~9.3%</td>\n",
       "      <td>34.4%~4.8%</td>\n",
       "      <td>35.5%~3.6%</td>\n",
       "      <td>35.5%~4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Net</th>\n",
       "      <td>40.0%~8.0%</td>\n",
       "      <td>35.1%~4.6%</td>\n",
       "      <td>35.4%~5.5%</td>\n",
       "      <td>35.9%~2.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>33.6%~9.1%</td>\n",
       "      <td>32.9%~5.8%</td>\n",
       "      <td>30.7%~4.1%</td>\n",
       "      <td>35.9%~3.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>32.1%~8.5%</td>\n",
       "      <td>32.0%~5.9%</td>\n",
       "      <td>33.7%~3.0%</td>\n",
       "      <td>35.1%~4.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0.8         0.6         0.4         0.2\n",
       "Nearest Neighbors 4  32.9%~7.1%  32.2%~7.1%  34.1%~4.3%  33.2%~5.1%\n",
       "Linear SVM           27.1%~8.2%  30.2%~4.1%  34.5%~4.1%  32.3%~2.5%\n",
       "Linear SVM MAGNN     35.7%~5.1%  37.6%~4.8%  37.3%~4.4%  35.6%~3.1%\n",
       "Decision Tree        37.1%~9.1%  39.5%~6.1%  36.4%~4.8%  33.5%~3.9%\n",
       "Random Forest        32.9%~9.3%  34.4%~4.8%  35.5%~3.6%  35.5%~4.0%\n",
       "Neural Net           40.0%~8.0%  35.1%~4.6%  35.4%~5.5%  35.9%~2.2%\n",
       "AdaBoost             33.6%~9.1%  32.9%~5.8%  30.7%~4.1%  35.9%~3.4%\n",
       "Naive Bayes          32.1%~8.5%  32.0%~5.9%  33.7%~3.0%  35.1%~4.4%"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tests_micro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "0f37d40a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_confusion_matrix(y_true, y_predicted):\n",
    "    classes = [-1, 0, 1]\n",
    "    true_actual_str = 'True/Actual'\n",
    "    predicted_str = 'Predicted'\n",
    "\n",
    "    MultiIndex_Columns = pd.MultiIndex.from_tuples(list(zip([true_actual_str]*3, classes)))\n",
    "    MultiIndex_Index = pd.MultiIndex.from_tuples(list(zip([predicted_str]*3, classes)))\n",
    "\n",
    "    df_true_predicted = pd.DataFrame(np.zeros((3,3)), columns = MultiIndex_Columns, index=MultiIndex_Index)\n",
    "    for truth, prediction in list(zip(y_true, y_predicted)):\n",
    "        df_true_predicted[true_actual_str, truth][predicted_str, prediction] += 1\n",
    "    df_true_predicted = df_true_predicted.astype(int)\n",
    "    return df_true_predicted    \n",
    "\n",
    "def get_classifier(target, names, classifiers):\n",
    "    for name, classifier in list(zip(names, classifiers)):\n",
    "        if name==target:\n",
    "            return classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "8199ee27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">True/Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Predicted</th>\n",
       "      <th>-1</th>\n",
       "      <td>16</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             True/Actual       \n",
       "                      -1  0   1\n",
       "Predicted -1          16  7   6\n",
       "           0           3  5   2\n",
       "           1           9  8  13"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = get_classifier('Decision Tree', names, classifiers)\n",
    "predicted = clf.predict(X_test)\n",
    "create_confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "ad54ccb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM test\n",
      "Macro-F1: 0.342111~0.053907 (0.8), 0.371087~0.049454 (0.6), 0.368230~0.045984 (0.4), 0.350353~0.029978 (0.2)\n",
      "Micro-F1: 0.357143~0.050508 (0.8), 0.376364~0.048139 (0.6), 0.373494~0.044104 (0.4), 0.356364~0.030641 (0.2)\n",
      "K-means test\n",
      "NMI: 0.003305~0.000000\n",
      "ARI: -0.010166~0.000000\n"
     ]
    }
   ],
   "source": [
    "from utils.tools import evaluate_results_nc\n",
    "\n",
    "out_dim = 3\n",
    "svm_macro_f1_list, svm_micro_f1_list, nmi_mean, nmi_std, ari_mean, ari_std = evaluate_results_nc(\n",
    "    X, y, num_classes=out_dim) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "95517ae5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.32791646468572044 0.06869385425159476\n",
      "0.33369565217391306 0.06898364234478431\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4308571696300982,\n",
       " 0.39716952725082805,\n",
       " 0.3244809047089358,\n",
       " 0.35738095238095235,\n",
       " 0.2619047619047619,\n",
       " 0.4047619047619048,\n",
       " 0.271604938271605,\n",
       " 0.34726576105886453,\n",
       " 0.2703619909502262,\n",
       " 0.2871805613741098,\n",
       " 0.27432126696832576,\n",
       " 0.35221674876847286,\n",
       " 0.3280022446689113,\n",
       " 0.29859943977591036,\n",
       " 0.36095238095238097,\n",
       " 0.28062678062678065,\n",
       " 0.14294750158127767,\n",
       " 0.36315505891723476,\n",
       " 0.30484151863462206,\n",
       " 0.4062397372742201,\n",
       " 0.34640522875817,\n",
       " 0.3482758620689655,\n",
       " 0.26612002376708255,\n",
       " 0.2613154960981048,\n",
       " 0.252262443438914,\n",
       " 0.32169312169312175,\n",
       " 0.31322751322751324,\n",
       " 0.30513070077864296,\n",
       " 0.2630684727458921,\n",
       " 0.3466583240637746,\n",
       " 0.32863355780022446,\n",
       " 0.3647992530345472,\n",
       " 0.41206529109754914,\n",
       " 0.2503303303303303,\n",
       " 0.3059757236227824,\n",
       " 0.27742027742027736,\n",
       " 0.3002380952380952,\n",
       " 0.3052048260381594,\n",
       " 0.37045791620318874,\n",
       " 0.37415824915824913,\n",
       " 0.2837401795735129,\n",
       " 0.2232422640031336,\n",
       " 0.3689747868001483,\n",
       " 0.26153846153846155,\n",
       " 0.41407168037602826,\n",
       " 0.2670442325614739,\n",
       " 0.306547619047619,\n",
       " 0.30158730158730157,\n",
       " 0.3214907697666319,\n",
       " 0.3094150443929065,\n",
       " 0.4035273368606702,\n",
       " 0.4129032258064516,\n",
       " 0.284780578898226,\n",
       " 0.20424836601307192,\n",
       " 0.34086075465385807,\n",
       " 0.3720238095238095,\n",
       " 0.3216729507052088,\n",
       " 0.3906810035842294,\n",
       " 0.32364532019704434,\n",
       " 0.3134563134563135,\n",
       " 0.3438311086392288,\n",
       " 0.21365377917102055,\n",
       " 0.3211629479377958,\n",
       " 0.3380816714150048,\n",
       " 0.23982683982683983,\n",
       " 0.3432098765432099,\n",
       " 0.4146987112504354,\n",
       " 0.34074074074074073,\n",
       " 0.2824372759856631,\n",
       " 0.43154761904761907,\n",
       " 0.33525525525525524,\n",
       " 0.43915343915343913,\n",
       " 0.4321142459073493,\n",
       " 0.34276018099547506,\n",
       " 0.3566934857257438,\n",
       " 0.3488536155202822,\n",
       " 0.4120001861937346,\n",
       " 0.3011934302256883,\n",
       " 0.3744343891402715,\n",
       " 0.42488755622188906,\n",
       " 0.3407407407407408,\n",
       " 0.335632183908046,\n",
       " 0.4257142857142857,\n",
       " 0.31834464555052794,\n",
       " 0.32302333681644024,\n",
       " 0.2798328108672936,\n",
       " 0.43779677113010446,\n",
       " 0.29045355515943755,\n",
       " 0.27884206045125587,\n",
       " 0.4328703703703704,\n",
       " 0.1990247300592128,\n",
       " 0.251559934318555,\n",
       " 0.18119658119658122,\n",
       " 0.30018674136321194,\n",
       " 0.2593795093795094,\n",
       " 0.3039426523297491,\n",
       " 0.2894736842105263,\n",
       " 0.28958020989505245,\n",
       " 0.3452380952380952,\n",
       " 0.2832512315270936,\n",
       " 0.39131989131989126,\n",
       " 0.30477586929199835,\n",
       " 0.2627919911012236,\n",
       " 0.3466286799620133,\n",
       " 0.3063101604278075,\n",
       " 0.35738095238095235,\n",
       " 0.43333333333333335,\n",
       " 0.23852695199943783,\n",
       " 0.2780081925243216,\n",
       " 0.25502645502645505,\n",
       " 0.33562724014336914,\n",
       " 0.3452455590386625,\n",
       " 0.35807486631016044,\n",
       " 0.38011695906432746,\n",
       " 0.32427725531173807,\n",
       " 0.3282051282051282,\n",
       " 0.40541871921182265,\n",
       " 0.26204776204776203,\n",
       " 0.2539967022725644,\n",
       " 0.3258369058495561,\n",
       " 0.4489688627619662,\n",
       " 0.34057045551298426,\n",
       " 0.1722222222222222,\n",
       " 0.2999622926093514,\n",
       " 0.3055555555555556,\n",
       " 0.3477866219801704,\n",
       " 0.372274468826193,\n",
       " 0.3571804062126643,\n",
       " 0.37352693602693604,\n",
       " 0.23839931885908897,\n",
       " 0.31749999999999995,\n",
       " 0.29959358944866193,\n",
       " 0.12891986062717772,\n",
       " 0.2607466063348416,\n",
       " 0.33500435919790755,\n",
       " 0.4135005973715651,\n",
       " 0.25415499533146596,\n",
       " 0.3692919983242564,\n",
       " 0.19010270774976656,\n",
       " 0.41469871125043545,\n",
       " 0.25904882154882153,\n",
       " 0.3028713222261609,\n",
       " 0.35916666666666663,\n",
       " 0.38963585434173664,\n",
       " 0.3390112801877508,\n",
       " 0.2636363636363636,\n",
       " 0.38588651491877296,\n",
       " 0.3259180035650624,\n",
       " 0.2373350361856109,\n",
       " 0.22385620915032678,\n",
       " 0.4638009049773755,\n",
       " 0.3264012675777382,\n",
       " 0.2579068360556564,\n",
       " 0.37102055033089515,\n",
       " 0.3837742504409171,\n",
       " 0.3210826210826211,\n",
       " 0.30933101985733563,\n",
       " 0.3938375350140056,\n",
       " 0.5296717171717171,\n",
       " 0.2791289592760181,\n",
       " 0.23158645276292336,\n",
       " 0.3441791183726668,\n",
       " 0.38404558404558403,\n",
       " 0.27723029658513537,\n",
       " 0.23597025016903314,\n",
       " 0.3979579579579579,\n",
       " 0.41164021164021164,\n",
       " 0.36210826210826214,\n",
       " 0.3690375982042649,\n",
       " 0.29735048141120246,\n",
       " 0.21666666666666665,\n",
       " 0.40168168168168167,\n",
       " 0.3443374925727867,\n",
       " 0.40684624017957355,\n",
       " 0.23749999999999996,\n",
       " 0.2343574635241302,\n",
       " 0.32616487455197135,\n",
       " 0.3142450142450142,\n",
       " 0.38987093153759816,\n",
       " 0.17361111111111108,\n",
       " 0.3386618876941458,\n",
       " 0.23254165189649065,\n",
       " 0.4047619047619048,\n",
       " 0.221358024691358,\n",
       " 0.2837401795735129,\n",
       " 0.3444187391555813,\n",
       " 0.29178338001867415,\n",
       " 0.2988953866146849,\n",
       " 0.25829562594268474,\n",
       " 0.43645717463848727,\n",
       " 0.4179033144550386,\n",
       " 0.42446633825944174,\n",
       " 0.35110771227289583,\n",
       " 0.2908108108108108,\n",
       " 0.3558785300720784,\n",
       " 0.37390128465179173,\n",
       " 0.36670296430732,\n",
       " 0.32616487455197135,\n",
       " 0.29534662867996203,\n",
       " 0.252728919395586,\n",
       " 0.261619709895572,\n",
       " 0.3715231005553586,\n",
       " 0.3177495462794918,\n",
       " 0.3180654470977052,\n",
       " 0.24305555555555555,\n",
       " 0.3947163947163947,\n",
       " 0.3869035179380007,\n",
       " 0.29817444219066935,\n",
       " 0.30654761904761907,\n",
       " 0.28589341692789966,\n",
       " 0.2664963814389102,\n",
       " 0.3506844033159822,\n",
       " 0.3458333333333334,\n",
       " 0.3478057889822596,\n",
       " 0.3935135135135135,\n",
       " 0.3264012675777382,\n",
       " 0.4383638583638583,\n",
       " 0.3183446455505279,\n",
       " 0.2232422640031336,\n",
       " 0.30354449472096534,\n",
       " 0.2769852080196908,\n",
       " 0.4340802987861811,\n",
       " 0.4566308243727599,\n",
       " 0.29108287961282514,\n",
       " 0.35000000000000003,\n",
       " 0.41081081081081083,\n",
       " 0.34920634920634924,\n",
       " 0.4677544677544678,\n",
       " 0.3478057889822596,\n",
       " 0.3282783882783883,\n",
       " 0.2026549750334916,\n",
       " 0.3058027437893956,\n",
       " 0.2215724496426251,\n",
       " 0.30968672904156774,\n",
       " 0.30607922543406413,\n",
       " 0.46481481481481496,\n",
       " 0.21666666666666665,\n",
       " 0.26106689009914813,\n",
       " 0.3000348310693138,\n",
       " 0.1643606471192678,\n",
       " 0.37150818530128876,\n",
       " 0.3433048433048433,\n",
       " 0.35042735042735046,\n",
       " 0.21064961229414106,\n",
       " 0.35042735042735046,\n",
       " 0.16255534471853256,\n",
       " 0.31944951893800994,\n",
       " 0.3316239316239316,\n",
       " 0.34447927551375823,\n",
       " 0.3258858858858859,\n",
       " 0.4052287581699347,\n",
       " 0.3050784341106922,\n",
       " 0.27265912338651116,\n",
       " 0.30053646309180787,\n",
       " 0.5133903133903134,\n",
       " 0.3623416965352449,\n",
       " 0.35463328941589817,\n",
       " 0.32473118279569896,\n",
       " 0.2414269107817495,\n",
       " 0.3878464169419262,\n",
       " 0.3504201680672268,\n",
       " 0.30147783251231525,\n",
       " 0.371326164874552,\n",
       " 0.30018674136321194,\n",
       " 0.45107376283846873,\n",
       " 0.43708133971291857,\n",
       " 0.3645021645021645,\n",
       " 0.38654746700723713,\n",
       " 0.282826153161384,\n",
       " 0.28065906562847603,\n",
       " 0.4977829188355504,\n",
       " 0.3624338624338625,\n",
       " 0.3039421997755331,\n",
       " 0.31417624521072796,\n",
       " 0.2819444444444445,\n",
       " 0.25415070242656446,\n",
       " 0.3624338624338625,\n",
       " 0.3256033182503771,\n",
       " 0.3635589612601107,\n",
       " 0.22112532443455693,\n",
       " 0.4134453781512604,\n",
       " 0.3173789173789174,\n",
       " 0.4791666666666667,\n",
       " 0.34814145346681497,\n",
       " 0.3224407171775593,\n",
       " 0.2927036199095023,\n",
       " 0.39344642195031515,\n",
       " 0.2536107536107536,\n",
       " 0.3705206220419202,\n",
       " 0.313190383365822,\n",
       " 0.3248190719455088,\n",
       " 0.29876543209876544,\n",
       " 0.29901960784313725,\n",
       " 0.23749999999999996,\n",
       " 0.30511463844797176,\n",
       " 0.204442868958998,\n",
       " 0.341871921182266,\n",
       " 0.35577200577200574,\n",
       " 0.375,\n",
       " 0.4101806239737274,\n",
       " 0.27413019079685746,\n",
       " 0.30389363722697055,\n",
       " 0.38975468975468974,\n",
       " 0.3030430810316958,\n",
       " 0.3273809523809524,\n",
       " 0.31723723723723724,\n",
       " 0.21442006269592476,\n",
       " 0.2799870226177234,\n",
       " 0.3847041847041847,\n",
       " 0.34863073066741634,\n",
       " 0.3894909688013137,\n",
       " 0.18801313628899838,\n",
       " 0.3820774797786292,\n",
       " 0.3700280112044818,\n",
       " 0.2853279242731575,\n",
       " 0.2212401795735129,\n",
       " 0.28687102371312895,\n",
       " 0.27309464728819566,\n",
       " 0.23412186379928315,\n",
       " 0.3575447570332481,\n",
       " 0.4344086021505377,\n",
       " 0.14730001181614083,\n",
       " 0.2709551656920078,\n",
       " 0.3666212631729873,\n",
       " 0.3458333333333334,\n",
       " 0.25972222222222224,\n",
       " 0.33886760323541926,\n",
       " 0.28315412186379935,\n",
       " 0.2533022533022533,\n",
       " 0.35191378669639545,\n",
       " 0.2579068360556564,\n",
       " 0.43594068451753465,\n",
       " 0.3019400352733686,\n",
       " 0.4497811131957474,\n",
       " 0.325,\n",
       " 0.3557509157509158,\n",
       " 0.47705390399887554,\n",
       " 0.34598628105302187,\n",
       " 0.32134646962233165,\n",
       " 0.3478748020947509,\n",
       " 0.30244473722734594,\n",
       " 0.4108309990662932,\n",
       " 0.32108262108262103,\n",
       " 0.2588645071403692,\n",
       " 0.18659611992945327,\n",
       " 0.3022988505747126,\n",
       " 0.31862745098039214,\n",
       " 0.3278799249530957,\n",
       " 0.28472368636821516,\n",
       " 0.19312169312169314,\n",
       " 0.39629629629629637,\n",
       " 0.3840455840455841,\n",
       " 0.2597222222222222,\n",
       " 0.4204639804639805,\n",
       " 0.2647935291613453,\n",
       " 0.46458739441195585,\n",
       " 0.39101745423584505,\n",
       " 0.3673234811165846,\n",
       " 0.3062463851937536,\n",
       " 0.25471342383107093,\n",
       " 0.37013610701150235,\n",
       " 0.4328805294322535,\n",
       " 0.46906906906906903,\n",
       " 0.23935091277890463,\n",
       " 0.30607922543406413,\n",
       " 0.39012846517917504,\n",
       " 0.34722222222222215,\n",
       " 0.45622895622895626,\n",
       " 0.39570823441791186,\n",
       " 0.15073891625615762,\n",
       " 0.3732407942934259,\n",
       " 0.3795039322444041,\n",
       " 0.33815307499518027,\n",
       " 0.36650246305418727,\n",
       " 0.39482746503619365,\n",
       " 0.3438231780167264,\n",
       " 0.2242717025325721,\n",
       " 0.25046594982078857,\n",
       " 0.3815073815073815,\n",
       " 0.3853357100415924,\n",
       " 0.270744215134459,\n",
       " 0.4751563707920445,\n",
       " 0.28032044583768717,\n",
       " 0.29751131221719457,\n",
       " 0.4321070234113713,\n",
       " 0.2799870226177234,\n",
       " 0.17082484128657438,\n",
       " 0.4218694885361552,\n",
       " 0.2946000236322817,\n",
       " 0.2251218062982769,\n",
       " 0.3592592592592592,\n",
       " 0.30243399629863893,\n",
       " 0.37347670250896065,\n",
       " 0.32010582010582017,\n",
       " 0.27887571365832237,\n",
       " 0.2599415204678362,\n",
       " 0.3396996996996997,\n",
       " 0.24270289097875306,\n",
       " 0.31036872416182765,\n",
       " 0.35139412558767397,\n",
       " 0.21987661461345667,\n",
       " 0.17038539553752532,\n",
       " 0.36774193548387096,\n",
       " 0.4121863799283154,\n",
       " 0.32870638133796026,\n",
       " 0.3528372655777374,\n",
       " 0.3764285714285714,\n",
       " 0.23668430335097002,\n",
       " 0.23942652329749103,\n",
       " 0.23416965352449223,\n",
       " 0.3975869809203143,\n",
       " 0.2162668665667166,\n",
       " 0.40694731999079825,\n",
       " 0.35402776782087125,\n",
       " 0.3866442199775533,\n",
       " 0.2527160493827161,\n",
       " 0.21337641989815903,\n",
       " 0.3416666666666666,\n",
       " 0.36921603300913647,\n",
       " 0.34946689113355783,\n",
       " 0.40378438765535535,\n",
       " 0.394404878275846,\n",
       " 0.39570079043763257,\n",
       " 0.3645482603815937,\n",
       " 0.32616487455197135,\n",
       " 0.2451058681185723,\n",
       " 0.23832035595105672,\n",
       " 0.23923945335710042,\n",
       " 0.3072265814201298,\n",
       " 0.2598257322951428,\n",
       " 0.3466089466089466,\n",
       " 0.17500000000000002,\n",
       " 0.36355896126011067,\n",
       " 0.3712643678160919,\n",
       " 0.4665328458431907,\n",
       " 0.38616981831664815,\n",
       " 0.2556272401433692,\n",
       " 0.41749257278669044,\n",
       " 0.2380952380952381,\n",
       " 0.21541081311196253,\n",
       " 0.34074074074074073,\n",
       " 0.3183446455505279,\n",
       " 0.33304093567251464,\n",
       " 0.1954719609892024,\n",
       " 0.283068783068783,\n",
       " 0.3247863247863248,\n",
       " 0.30623973727422,\n",
       " 0.2789432789432789,\n",
       " 0.2179606662365283,\n",
       " 0.4033159822633507,\n",
       " 0.3280022446689113,\n",
       " 0.27976190476190477,\n",
       " 0.4138888888888889,\n",
       " 0.41250000000000003,\n",
       " 0.26311858076563954,\n",
       " 0.401010101010101,\n",
       " 0.2802479899254093,\n",
       " 0.44182892569989346,\n",
       " 0.2894848871860366,\n",
       " 0.32393937264272493,\n",
       " 0.4247863247863248,\n",
       " 0.23832035595105672,\n",
       " 0.41311697092630156,\n",
       " 0.358281911675741,\n",
       " 0.48031034987556726,\n",
       " 0.30512180629827695,\n",
       " 0.37354497354497357,\n",
       " 0.2584175084175084,\n",
       " 0.35784313725490197,\n",
       " 0.33095238095238094,\n",
       " 0.30428571428571427,\n",
       " 0.2419191919191919,\n",
       " 0.2616509926854754,\n",
       " 0.30718954248366015,\n",
       " 0.27321937321937323,\n",
       " 0.3697251258226868,\n",
       " 0.290652557319224,\n",
       " 0.30751751118607545,\n",
       " 0.3045843045843046,\n",
       " 0.3679012345679012,\n",
       " 0.36713995943204863,\n",
       " 0.3282247765006386,\n",
       " 0.3658263305322129,\n",
       " 0.3203378817413905,\n",
       " 0.39012846517917515,\n",
       " 0.33103926207374484,\n",
       " 0.34616434616434616,\n",
       " 0.29392911010558065,\n",
       " 0.2635434740697899,\n",
       " 0.3872918010849045,\n",
       " 0.3452380952380953,\n",
       " 0.3474548440065682,\n",
       " 0.4386933352450593,\n",
       " 0.38086021505376344,\n",
       " 0.21737891737891735,\n",
       " 0.27653844320510984,\n",
       " 0.35070443872140583,\n",
       " 0.3248190719455087,\n",
       " 0.3799533799533799,\n",
       " 0.2849694104560623,\n",
       " 0.3007469654528478,\n",
       " 0.28023767082590606,\n",
       " 0.3520074696545285,\n",
       " 0.19119769119769117,\n",
       " 0.36863053529720197,\n",
       " 0.4035892422989198,\n",
       " 0.3444444444444444,\n",
       " 0.30485304169514693,\n",
       " 0.32416225749559086,\n",
       " 0.21288749564611634,\n",
       " 0.365,\n",
       " 0.29564652371669914,\n",
       " 0.43476430976430974,\n",
       " 0.284780578898226,\n",
       " 0.3137029368913427,\n",
       " 0.42018018018018016,\n",
       " 0.3666666666666667,\n",
       " 0.3368309110244594,\n",
       " 0.299845513963161,\n",
       " 0.38392857142857145,\n",
       " 0.259652878660448,\n",
       " 0.4067019400352734,\n",
       " 0.2935960591133005,\n",
       " 0.36944444444444446,\n",
       " 0.3489844683393071,\n",
       " 0.41311697092630156,\n",
       " 0.2844022884673291,\n",
       " 0.3084315375982043,\n",
       " 0.29886421821905695,\n",
       " 0.31900584795321635,\n",
       " 0.321514645902855,\n",
       " 0.1958333333333333,\n",
       " 0.37083333333333335,\n",
       " 0.17143788111530048,\n",
       " 0.2997076023391813,\n",
       " 0.19642857142857142,\n",
       " 0.25676937441643327,\n",
       " 0.3441514536849222,\n",
       " 0.33795248868778277,\n",
       " 0.28774928774928776,\n",
       " 0.4546428571428571,\n",
       " 0.33824733824733827,\n",
       " 0.20788177339901479,\n",
       " 0.38746438746438744,\n",
       " 0.35808080808080806,\n",
       " 0.3197044334975369,\n",
       " 0.3250433776749566,\n",
       " 0.25972222222222224,\n",
       " 0.23499940919295756,\n",
       " 0.3732009925558313,\n",
       " 0.2999622926093514,\n",
       " 0.3360097498028533,\n",
       " 0.2980629827688651,\n",
       " 0.3171296296296296,\n",
       " 0.3209876543209876,\n",
       " 0.33510575446059315,\n",
       " 0.23492063492063495,\n",
       " 0.35996907723662946,\n",
       " 0.24442002442002442,\n",
       " 0.32690476190476186,\n",
       " 0.29629629629629634,\n",
       " 0.25526315789473686,\n",
       " 0.2619047619047619,\n",
       " 0.3247863247863248,\n",
       " 0.3259640341119763,\n",
       " 0.32296918767507005,\n",
       " 0.2898212898212898,\n",
       " 0.25846017781501657,\n",
       " 0.36283902950569624,\n",
       " 0.29476104053236535,\n",
       " 0.3221674876847291,\n",
       " 0.37150818530128876,\n",
       " 0.28057889822595705,\n",
       " 0.2740740740740741,\n",
       " 0.44089366515837103,\n",
       " 0.32108262108262103,\n",
       " 0.3062463851937536,\n",
       " 0.27280701754385966,\n",
       " 0.35495818399044204,\n",
       " 0.2380952380952381,\n",
       " 0.23791786726638087,\n",
       " 0.3782828282828283,\n",
       " 0.2691919191919192,\n",
       " 0.32416225749559086,\n",
       " 0.41494252873563214,\n",
       " 0.30433152950547004,\n",
       " 0.3951361161524501,\n",
       " 0.3905022446689113,\n",
       " 0.21409035409035407,\n",
       " 0.34531423804226913,\n",
       " 0.3242772553117381,\n",
       " 0.3422619047619047,\n",
       " 0.23473188558577554,\n",
       " 0.2866066066066066,\n",
       " 0.4105137395459976,\n",
       " 0.35146198830409353,\n",
       " 0.3196612220205686,\n",
       " 0.5028944911297852,\n",
       " 0.48660660660660665,\n",
       " 0.45551298424861647,\n",
       " 0.3443349753694582,\n",
       " 0.4564102564102564,\n",
       " 0.3389715668481548,\n",
       " 0.4289241622574956,\n",
       " 0.37602627257799665,\n",
       " 0.25684430512016715,\n",
       " 0.2846082156426984,\n",
       " 0.4689458689458689,\n",
       " 0.2863876319758672,\n",
       " 0.23139443791617706,\n",
       " 0.36863053529720197,\n",
       " 0.27477954144620814,\n",
       " 0.36256157635467984,\n",
       " 0.3281192065257694,\n",
       " 0.1729931405265109,\n",
       " 0.34447927551375823,\n",
       " 0.4244852062688875,\n",
       " 0.24777731229344133,\n",
       " 0.36948798328108673,\n",
       " 0.38690476190476186,\n",
       " 0.41330049261083746,\n",
       " 0.28310886644219974,\n",
       " 0.3226737420285808,\n",
       " 0.3438231780167264,\n",
       " 0.35369827305311174,\n",
       " 0.27724867724867724,\n",
       " 0.4101806239737274,\n",
       " 0.3919632925472747,\n",
       " 0.1970211161387632,\n",
       " 0.18999323867478024,\n",
       " 0.45236254597418424,\n",
       " 0.3839773130095711,\n",
       " 0.3469534050179211,\n",
       " 0.28052612349287537,\n",
       " 0.5003584229390682,\n",
       " 0.3485196795541623,\n",
       " 0.26064043483398325,\n",
       " 0.24345076784101174,\n",
       " 0.34767025089605735,\n",
       " 0.17419354838709677,\n",
       " 0.3984789067142009,\n",
       " 0.3129785247432307,\n",
       " 0.3273809523809524,\n",
       " 0.40229885057471265,\n",
       " 0.26045108838185155,\n",
       " 0.3680555555555556,\n",
       " 0.2846394984326019,\n",
       " 0.2638888888888889,\n",
       " 0.2819556957487992,\n",
       " 0.3466286799620133,\n",
       " 0.2361823361823362,\n",
       " 0.3398569023569024,\n",
       " 0.25452380952380954,\n",
       " 0.45291005291005293,\n",
       " 0.32712535432333034,\n",
       " 0.30331088664422,\n",
       " 0.3923945335710042,\n",
       " 0.28243021346469627,\n",
       " 0.32448090470893587,\n",
       " 0.2600323283435238,\n",
       " 0.25631467010777353,\n",
       " 0.3624338624338624,\n",
       " 0.32888795792021597,\n",
       " 0.3007154882154882,\n",
       " 0.5029761904761905,\n",
       " 0.27766830870279147,\n",
       " 0.374294670846395,\n",
       " 0.3028213166144201,\n",
       " 0.27996555415910257,\n",
       " 0.34567901234567905,\n",
       " 0.1730821730821731,\n",
       " 0.2993372265480163,\n",
       " 0.3203378817413905,\n",
       " 0.32838674217984565,\n",
       " 0.47236467236467233,\n",
       " 0.252728919395586,\n",
       " 0.1956989247311828,\n",
       " 0.30567542332248215,\n",
       " 0.3194533571004159,\n",
       " 0.2625,\n",
       " 0.30433152950547004,\n",
       " 0.4239375244810028,\n",
       " 0.3979107312440646,\n",
       " 0.35371424555485276,\n",
       " 0.2783002438174852,\n",
       " 0.28185301288749565,\n",
       " 0.21266504599837935,\n",
       " 0.4060885351207932,\n",
       " 0.39012345679012345,\n",
       " 0.24532382650029713,\n",
       " 0.22385620915032678,\n",
       " 0.28532356532356534,\n",
       " 0.37456140350877193,\n",
       " 0.41432748538011693,\n",
       " 0.34544474898681093,\n",
       " 0.5017911010558069,\n",
       " 0.3195701357466063,\n",
       " 0.3197945845004669,\n",
       " 0.37424242424242427,\n",
       " 0.2473491420859842,\n",
       " 0.3928571428571428,\n",
       " 0.24612612612612614,\n",
       " 0.30147783251231525,\n",
       " 0.4288288288288289,\n",
       " 0.3273809523809524,\n",
       " 0.3405716147651632,\n",
       " 0.31780007432181345,\n",
       " 0.28345238095238096,\n",
       " 0.25115374704242505,\n",
       " 0.2123249299719888,\n",
       " 0.3123123123123123,\n",
       " 0.2954809648358035,\n",
       " 0.4999046665713333,\n",
       " 0.32440476190476186,\n",
       " 0.1873873873873874,\n",
       " 0.27477954144620814,\n",
       " 0.40121381886087765,\n",
       " 0.5118437118437118,\n",
       " 0.32047369950595755,\n",
       " 0.3841441441441442,\n",
       " 0.34883557800224474,\n",
       " 0.34863073066741634,\n",
       " 0.527833519137867,\n",
       " 0.3777317690361168,\n",
       " 0.3414462081128748,\n",
       " 0.4204639804639805,\n",
       " 0.4157357357357357,\n",
       " 0.29065255731922396,\n",
       " 0.31844974948423227,\n",
       " 0.3273541497502522,\n",
       " 0.39809902740937225,\n",
       " 0.3186462324393359,\n",
       " 0.2216636410184797,\n",
       " 0.32138188608776846,\n",
       " 0.3959199841552783,\n",
       " 0.30952380952380953,\n",
       " 0.31300665456745314,\n",
       " 0.3395493395493396,\n",
       " 0.33304093567251464,\n",
       " 0.41447245564892626,\n",
       " 0.4148148148148148,\n",
       " 0.37606837606837606,\n",
       " 0.3910533910533911,\n",
       " 0.3259640341119763,\n",
       " 0.3015873015873016,\n",
       " 0.32225705329153603,\n",
       " 0.34350079744816586,\n",
       " 0.30686172065482414,\n",
       " 0.28935185185185186,\n",
       " 0.3566137566137566,\n",
       " 0.36544757924068266,\n",
       " 0.3701234567901235,\n",
       " 0.3897439501487572,\n",
       " 0.3438231780167264,\n",
       " 0.4338624338624339,\n",
       " 0.3509803921568628,\n",
       " 0.3474694104560623,\n",
       " 0.3642178910544727,\n",
       " 0.285978736710444,\n",
       " 0.443001443001443,\n",
       " 0.2966666666666667,\n",
       " 0.34861111111111115,\n",
       " 0.1995331465919701,\n",
       " 0.30243399629863893,\n",
       " 0.3364672364672365,\n",
       " 0.40526018099547506,\n",
       " 0.2512378688849277,\n",
       " 0.359427022841657,\n",
       " 0.3933696309739867,\n",
       " 0.5453115547489413,\n",
       " 0.3538324420677362,\n",
       " 0.36338259441707715,\n",
       " 0.2863711001642036,\n",
       " 0.3467973674453096,\n",
       " 0.3837992831541219,\n",
       " 0.28715728715728717,\n",
       " 0.3033613445378151,\n",
       " 0.3014778325123153,\n",
       " 0.3898809523809524,\n",
       " 0.36840628507295176,\n",
       " 0.26973572037510657,\n",
       " 0.3449775533108866,\n",
       " 0.3376446230666179,\n",
       " 0.27535014005602243,\n",
       " 0.32142857142857145,\n",
       " 0.3264012675777382,\n",
       " 0.314338147671481,\n",
       " 0.4331691297208539,\n",
       " 0.3244809047089358,\n",
       " 0.27963772791359,\n",
       " 0.30532907952262783,\n",
       " 0.22819039198349544,\n",
       " 0.20457350272232303,\n",
       " 0.2680652680652681,\n",
       " 0.27790346907993974,\n",
       " 0.34105763517528226,\n",
       " 0.2927036199095023,\n",
       " 0.32393937264272493,\n",
       " 0.32091750841750843,\n",
       " 0.47760141093474423,\n",
       " 0.43120141507238285,\n",
       " 0.3119952210274791,\n",
       " 0.3958333333333333,\n",
       " 0.36246642246642247,\n",
       " 0.3045843045843046,\n",
       " 0.31936880323977096,\n",
       " 0.3539804171988081,\n",
       " 0.3928571428571428,\n",
       " 0.23049537948795637,\n",
       " 0.4320191158900836,\n",
       " 0.4045400238948626,\n",
       " 0.34531423804226913,\n",
       " 0.32663607712272896,\n",
       " 0.4484934420418291,\n",
       " 0.32616487455197135,\n",
       " 0.24361046688687424,\n",
       " 0.2599439775910364,\n",
       " 0.33886760323541926,\n",
       " 0.3399845768266821,\n",
       " 0.3045977011494253,\n",
       " 0.32157287157287157,\n",
       " 0.25415070242656446,\n",
       " 0.2116335771508185,\n",
       " 0.2387096774193548,\n",
       " 0.34390390390390385,\n",
       " 0.42829832485004893,\n",
       " 0.19444444444444442,\n",
       " 0.3698924731182796,\n",
       " 0.35625996810207333,\n",
       " 0.3015551048005409,\n",
       " 0.3517428807751388,\n",
       " 0.3908313908313908,\n",
       " 0.375,\n",
       " 0.38825031928480197,\n",
       " 0.298736802413273,\n",
       " 0.2323123123123123,\n",
       " 0.34517519466073415,\n",
       " 0.41005291005291006,\n",
       " 0.391291249536522,\n",
       " 0.4302749719416386,\n",
       " 0.3424590734935562,\n",
       " 0.3642178910544727,\n",
       " 0.285,\n",
       " 0.4067019400352734,\n",
       " 0.31377234286785205,\n",
       " 0.30457351290684626,\n",
       " 0.34838709677419355,\n",
       " 0.3752913752913753,\n",
       " 0.38327352472089316,\n",
       " 0.5312899106002554,\n",
       " 0.2663139329805997,\n",
       " 0.32075339096211963,\n",
       " 0.38960976892011373,\n",
       " 0.40046296296296297,\n",
       " 0.32515294771968856,\n",
       " 0.3790933790933791,\n",
       " 0.3628390295056962,\n",
       " 0.3165845648604269,\n",
       " 0.28703703703703703,\n",
       " 0.3876698014629049,\n",
       " 0.31928571428571423,\n",
       " 0.2581826775375163,\n",
       " 0.25392817059483724,\n",
       " 0.3995247029393371,\n",
       " 0.3283625730994152,\n",
       " 0.3205254515599343,\n",
       " 0.45510275165447583,\n",
       " 0.30604938271604937,\n",
       " 0.4101547199373286,\n",
       " 0.36375929682217717,\n",
       " 0.3702686202686203,\n",
       " 0.2530512802492562,\n",
       " 0.3439856711915535,\n",
       " 0.3210714285714286,\n",
       " 0.30513070077864296,\n",
       " 0.3947063688999173,\n",
       " 0.21611952861952863,\n",
       " 0.3187301587301587,\n",
       " 0.2871794871794872,\n",
       " 0.45404928738262074,\n",
       " 0.2962962962962963,\n",
       " 0.23171181811471175,\n",
       " 0.34447927551375823,\n",
       " 0.3068617206548241,\n",
       " 0.3436041083099907,\n",
       " 0.3497619047619047,\n",
       " 0.38726445743989607,\n",
       " 0.23650793650793656,\n",
       " 0.3461538461538461,\n",
       " 0.428298324850049,\n",
       " 0.3175248419150858,\n",
       " 0.3036475713756025,\n",
       " 0.39506172839506176,\n",
       " 0.2956577266922094,\n",
       " 0.25835667600373485,\n",
       " 0.4761904761904762,\n",
       " 0.2588472964943553,\n",
       " 0.39035087719298245,\n",
       " 0.3035714285714286,\n",
       " 0.3816091954022989,\n",
       " 0.3084315375982043,\n",
       " 0.23169129720853857,\n",
       " 0.3078827490592197,\n",
       " 0.1904326844238293,\n",
       " 0.3860981912144703,\n",
       " 0.5202279202279202,\n",
       " 0.27074693741360406,\n",
       " 0.38845550167498305,\n",
       " 0.21849849849849848,\n",
       " 0.37085218702865763,\n",
       " 0.4112933634992458,\n",
       " 0.24068268895855105,\n",
       " 0.33411033411033414,\n",
       " 0.46538461538461545,\n",
       " 0.4370763336280578,\n",
       " 0.2533022533022533,\n",
       " 0.34625024098708307,\n",
       " 0.30018018018018017,\n",
       " 0.3309568480300188,\n",
       " 0.3513227513227513,\n",
       " 0.37083333333333335,\n",
       " 0.2881807081807082,\n",
       " 0.3652421652421652,\n",
       " 0.3005952380952381,\n",
       " 0.30784718505492265,\n",
       " 0.2796401714807787,\n",
       " 0.18203463203463202,\n",
       " 0.2996706383803158,\n",
       " 0.3203490847169008,\n",
       " 0.3742017879948915,\n",
       " 0.36195719529052867,\n",
       " 0.37806637806637805,\n",
       " 0.3776860537836148,\n",
       " 0.2846320346320346,\n",
       " 0.41133557800224474,\n",
       " 0.1958333333333333,\n",
       " 0.30366366366366365,\n",
       " 0.33564814814814814,\n",
       " 0.3407407407407408,\n",
       " 0.30523627075351206,\n",
       " 0.34861111111111115,\n",
       " 0.238752052545156,\n",
       " 0.30493576741041245,\n",
       " 0.2749022314239706,\n",
       " 0.44064577397910726,\n",
       " 0.345679012345679,\n",
       " 0.2830687830687831,\n",
       " 0.40684624017957355,\n",
       " 0.3660130718954248,\n",
       " 0.3933218933218933,\n",
       " 0.3571804062126643,\n",
       " 0.37957692037388435,\n",
       " 0.19598164627363734,\n",
       " 0.3188558577552885,\n",
       " 0.2596801346801347,\n",
       " 0.27678571428571425,\n",
       " 0.4716394716394716,\n",
       " 0.4760683760683761,\n",
       " 0.29199360650973555,\n",
       " 0.26963938728644604,\n",
       " 0.35124434389140274,\n",
       " 0.3679886421821905,\n",
       " 0.2278469079939668,\n",
       " 0.3140713853599516,\n",
       " 0.4134296898524541,\n",
       " 0.3436041083099907,\n",
       " 0.3366056166056166,\n",
       " 0.3677487010820344,\n",
       " 0.30527472527472527,\n",
       " 0.34163473818646234,\n",
       " 0.4096960387282968,\n",
       " 0.23166715102198973,\n",
       " 0.2824372759856631,\n",
       " 0.3284072249589491,\n",
       " 0.3372923840982032,\n",
       " 0.313960113960114,\n",
       " 0.30379928315412186,\n",
       " 0.32084260289210237,\n",
       " 0.19931836598503264,\n",
       " 0.4330065359477124,\n",
       " 0.3203695945631429,\n",
       " 0.47426523297491047,\n",
       " 0.24992503748125938,\n",
       " 0.2600323283435238,\n",
       " 0.28243727598566304,\n",
       " 0.27069704489059326,\n",
       " 0.3414382552313587,\n",
       " 0.3625730994152047,\n",
       " 0.25074074074074076,\n",
       " 0.36802894848871864,\n",
       " 0.39263533555802743,\n",
       " 0.3861890797374668,\n",
       " 0.30579297245963916,\n",
       " 0.3913978494623656,\n",
       " 0.2916666666666667,\n",
       " 0.23534097031883242,\n",
       " 0.41006787330316746,\n",
       " 0.19424661360145234,\n",
       " 0.25341130604288503,\n",
       " 0.2620676814225202]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "macro_f1_list = []\n",
    "micro_f1_list = []\n",
    "for i in range(1000):\n",
    "    y_random_pred = np.random.randint(low=-1, high=2, size=len(y_test))\n",
    "    macro_f1_list.append(f1_score(y_test, y_random_pred, average='macro'))\n",
    "    micro_f1_list.append(f1_score(y_test, y_random_pred, average='micro'))\n",
    "print(np.mean(macro_f1_list), np.std(macro_f1_list))\n",
    "print(np.mean(micro_f1_list), np.std(micro_f1_list))\n",
    "macro_f1_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
