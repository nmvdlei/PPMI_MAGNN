{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a8dd3f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import scipy\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "from sklearn.metrics import f1_score, SCORERS\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC, LinearSVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
    "\n",
    "from utils.tools import evaluate_results_nc\n",
    "from utils.data import load_PPMI_data\n",
    "import data_utils as du\n",
    "\n",
    "data_dir = du.find_data_dir('app')\n",
    "dataloader_file = du.get_file_path(data_dir, 'class based structure', 'dataloaders', 'dataloader.p')\n",
    "dataloader = du.read_from_pickle(dataloader_file)\n",
    "adjlists, edge_metapath_indices_list, features_list, adjM, type_mask, labels, train_val_test_idx = load_PPMI_data()\n",
    "\n",
    "train_idx = train_val_test_idx['train_idx']\n",
    "train_idx = np.sort(train_idx)\n",
    "test_idx = train_val_test_idx['test_idx']\n",
    "test_idx = np.sort(test_idx)\n",
    "val_idx = train_val_test_idx['val_idx']\n",
    "val_idx = np.sort(val_idx)\n",
    "\n",
    "names = [\"Nearest Neighbors 4\", \"Linear SVM\", \"Linear SVM MAGNN\",\n",
    "         \"Decision Tree\", \"Random Forest\", \"Neural Net\", \"AdaBoost\",\n",
    "         \"Naive Bayes\"]\n",
    "\n",
    "classifiers = [\n",
    "    KNeighborsClassifier(4),\n",
    "    SVC(kernel=\"linear\", C=0.025),\n",
    "    LinearSVC(dual=False),\n",
    "    DecisionTreeClassifier(max_depth=5),\n",
    "    RandomForestClassifier(max_depth=5, n_estimators=100, max_features=1),\n",
    "    MLPClassifier(alpha=1, max_iter=1000),\n",
    "    AdaBoostClassifier(),\n",
    "    GaussianNB()\n",
    "]\n",
    "\n",
    "X, y = dataloader.X.iloc[test_idx].values, np.array(dataloader.y.iloc[test_idx]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "893c7e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style  type=\"text/css\" >\n",
       "</style><table id=\"T_3e62c_\" ><thead>    <tr>        <th class=\"blank level0\" ></th>        <th class=\"col_heading level0 col0\" >Amount</th>        <th class=\"col_heading level0 col1\" >Percentage</th>    </tr></thead><tbody>\n",
       "                <tr>\n",
       "                        <th id=\"T_3e62c_level0_row0\" class=\"row_heading level0 row0\" >-1</th>\n",
       "                        <td id=\"T_3e62c_row0_col0\" class=\"data row0 col0\" >91</td>\n",
       "                        <td id=\"T_3e62c_row0_col1\" class=\"data row0 col1\" >39.9%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3e62c_level0_row1\" class=\"row_heading level0 row1\" >0</th>\n",
       "                        <td id=\"T_3e62c_row1_col0\" class=\"data row1 col0\" >70</td>\n",
       "                        <td id=\"T_3e62c_row1_col1\" class=\"data row1 col1\" >30.7%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3e62c_level0_row2\" class=\"row_heading level0 row2\" >1</th>\n",
       "                        <td id=\"T_3e62c_row2_col0\" class=\"data row2 col0\" >67</td>\n",
       "                        <td id=\"T_3e62c_row2_col1\" class=\"data row2 col1\" >29.4%</td>\n",
       "            </tr>\n",
       "            <tr>\n",
       "                        <th id=\"T_3e62c_level0_row3\" class=\"row_heading level0 row3\" >Total</th>\n",
       "                        <td id=\"T_3e62c_row3_col0\" class=\"data row3 col0\" >228</td>\n",
       "                        <td id=\"T_3e62c_row3_col1\" class=\"data row3 col1\" >100.0%</td>\n",
       "            </tr>\n",
       "    </tbody></table>"
      ],
      "text/plain": [
       "<pandas.io.formats.style.Styler at 0x7f161c07dfa0>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataloader.target_distribution_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03804adc",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "c7c89ee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clf_test(X, y, clf, test_sizes=(0.2, 0.4, 0.6, 0.8), repeat=10):\n",
    "    random_states = [182318 + i for i in range(repeat)]\n",
    "    result_macro_f1_list = []\n",
    "    result_micro_f1_list = []\n",
    "    for test_size in test_sizes:\n",
    "        macro_f1_list = []\n",
    "        micro_f1_list = []\n",
    "        for i in range(repeat):\n",
    "            X_train, X_test, y_train, y_test = train_test_split(\n",
    "                X, y, test_size=test_size, shuffle=True, random_state=random_states[i])\n",
    "            clf.fit(X_train, y_train)\n",
    "            y_pred = clf.predict(X_test)\n",
    "            macro_f1 = f1_score(y_test, y_pred, average='macro')\n",
    "            micro_f1 = f1_score(y_test, y_pred, average='micro')\n",
    "            macro_f1_list.append(macro_f1)\n",
    "            micro_f1_list.append(micro_f1)\n",
    "        result_macro_f1_list.append((np.mean(macro_f1_list), np.std(macro_f1_list)))\n",
    "        result_micro_f1_list.append((np.mean(micro_f1_list), np.std(micro_f1_list)))\n",
    "    return result_macro_f1_list, result_micro_f1_list\n",
    "\n",
    "def format_mean_std(mean_std):\n",
    "    mean, std = mean_std\n",
    "    mean_perc = mean*100\n",
    "    std_perc = std*100\n",
    "    return f'{mean_perc:.1f}%~{std_perc:.1f}%'\n",
    "\n",
    "def create_confusion_matrix(y_true, y_predicted):\n",
    "    classes = [-1, 0, 1]\n",
    "    true_actual_str = 'True/Actual'\n",
    "    predicted_str = 'Predicted'\n",
    "\n",
    "    MultiIndex_Columns = pd.MultiIndex.from_tuples(list(zip([true_actual_str]*3, classes)))\n",
    "    MultiIndex_Index = pd.MultiIndex.from_tuples(list(zip([predicted_str]*3, classes)))\n",
    "\n",
    "    df_true_predicted = pd.DataFrame(np.zeros((3,3)), columns = MultiIndex_Columns, index=MultiIndex_Index)\n",
    "    for truth, prediction in list(zip(y_true, y_predicted)):\n",
    "        df_true_predicted[true_actual_str, truth][predicted_str, prediction] += 1\n",
    "    df_true_predicted = df_true_predicted.astype(int)\n",
    "    return df_true_predicted    \n",
    "\n",
    "def get_classifier(target, names, classifiers):\n",
    "    for name, classifier in list(zip(names, classifiers)):\n",
    "        if name==target:\n",
    "            return classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62d975",
   "metadata": {},
   "source": [
    "### Making random guesses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "80170cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro: : 33.1%~7.0%\n",
      "Micro: : 33.6%~6.9%\n"
     ]
    }
   ],
   "source": [
    "macro_f1_list = []\n",
    "micro_f1_list = []\n",
    "for i in range(1000):\n",
    "    y_random_pred = np.random.randint(low=-1, high=2, size=len(y_test))\n",
    "    macro_f1_list.append(f1_score(y_test, y_random_pred, average='macro'))\n",
    "    micro_f1_list.append(f1_score(y_test, y_random_pred, average='micro'))\n",
    "print('Macro: :', format_mean_std((np.mean(macro_f1_list), np.std(macro_f1_list))))\n",
    "print('Micro: :', format_mean_std((np.mean(micro_f1_list), np.std(micro_f1_list))))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fdf36f",
   "metadata": {},
   "source": [
    "### Predicting most common class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "7a52cd06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Macro: : 19.5%\n",
      "Micro: : 41.3%\n"
     ]
    }
   ],
   "source": [
    "y_common_class_pred = np.repeat(-1, len(y_test))\n",
    "macro_common = f1_score(y_test, y_common_class_pred, average='macro')*100\n",
    "micro_common = f1_score(y_test, y_common_class_pred, average='micro')*100\n",
    "\n",
    "print('Macro: :', f'{macro_common:.1f}%')\n",
    "print('Micro: :', f'{micro_common:.1f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26c6b6d",
   "metadata": {},
   "source": [
    "### Create sample confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ded9dd6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shapes X, y (92, 253) (92,)\n",
      "Macro: : 45.8%\n",
      "Micro: : 47.8%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">True/Actual</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>-1</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Predicted</th>\n",
       "      <th>-1</th>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             True/Actual      \n",
       "                      -1  0  1\n",
       "Predicted -1          12  6  3\n",
       "           0           6  6  6\n",
       "           1           1  2  4"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = get_classifier('Decision Tree', names, classifiers)\n",
    "\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, test_size=.5, random_state=43)\n",
    "\n",
    "print('shapes X, y', X.shape, y.shape)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predicted = clf.predict(X_test)\n",
    "\n",
    "macro_sample = f1_score(y_test, predicted, average='macro')*100\n",
    "micro_sample = f1_score(y_test, predicted, average='micro')*100\n",
    "print('Macro: :', f'{macro_sample:.1f}%')\n",
    "print('Micro: :', f'{micro_sample:.1f}%')\n",
    "\n",
    "create_confusion_matrix(y_test, predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1a7b4a",
   "metadata": {},
   "source": [
    "### Perform statistical tests with baselines for good comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "db482fbe",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-62-2712f1ce308f>\u001b[0m in \u001b[0;36mclf_test\u001b[0;34m(X, y, clf, test_sizes, repeat)\u001b[0m\n\u001b[1;32m      9\u001b[0m             X_train, X_test, y_train, y_test = train_test_split(\n\u001b[1;32m     10\u001b[0m                 X, y, test_size=test_size, shuffle=True, random_state=random_states[i])\n\u001b[0;32m---> 11\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m             \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m             \u001b[0mmacro_f1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf1_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'macro'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    385\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    386\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 387\u001b[0;31m             trees = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[1;32m    388\u001b[0m                              \u001b[0;34m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'threads'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                 delayed(_parallel_build_trees)(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1042\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1043\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1044\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1045\u001b[0m                 \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    857\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    775\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    776\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 777\u001b[0;31m             \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    778\u001b[0m             \u001b[0;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m             \u001b[0;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    570\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 572\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    260\u001b[0m         \u001b[0;31m# change the default number of processes to -1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m             return [func(*args, **kwargs)\n\u001b[0m\u001b[1;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    220\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[0;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight, n_samples_bootstrap)\u001b[0m\n\u001b[1;32m    167\u001b[0m                                                         indices=indices)\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m         \u001b[0mtree\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \"\"\"\n\u001b[1;32m    897\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 898\u001b[0;31m         super().fit(\n\u001b[0m\u001b[1;32m    899\u001b[0m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/tree/_classes.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDOUBLE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mexpanded_class_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_check_sample_weight\u001b[0;34m(sample_weight, X, dtype)\u001b[0m\n\u001b[1;32m   1302\u001b[0m        \u001b[0mValidated\u001b[0m \u001b[0msample\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mIt\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mguaranteed\u001b[0m \u001b[0mto\u001b[0m \u001b[0mbe\u001b[0m \u001b[0;34m\"C\"\u001b[0m \u001b[0mcontiguous\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m     \"\"\"\n\u001b[0;32m-> 1304\u001b[0;31m     \u001b[0mn_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1305\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1306\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train_sizes = [0.8, 0.6, 0.4, 0.2]\n",
    "df_tests_macro = pd.DataFrame([], columns=train_sizes)\n",
    "df_tests_micro = pd.DataFrame([], columns=train_sizes)\n",
    "\n",
    "for name, clf in list(zip(names, classifiers)):\n",
    "    result_macro_f1_list, result_micro_f1_list = clf_test(X, y, clf)\n",
    "    df_tests_macro = df_tests_macro.append(pd.Series(result_macro_f1_list, index=train_sizes, name='TEST').apply(format_mean_std), ignore_index=True)\n",
    "    df_tests_micro = df_tests_micro.append(pd.Series(result_micro_f1_list, index=train_sizes, name='TEST').apply(format_mean_std), ignore_index=True)\n",
    "df_tests_macro.index = names\n",
    "df_tests_micro.index = names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "ddc56789",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors 4</th>\n",
       "      <td>31.7%~7.5%</td>\n",
       "      <td>31.0%~7.3%</td>\n",
       "      <td>32.2%~4.4%</td>\n",
       "      <td>32.0%~5.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>25.8%~8.0%</td>\n",
       "      <td>27.9%~6.3%</td>\n",
       "      <td>30.2%~4.1%</td>\n",
       "      <td>27.4%~3.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM MAGNN</th>\n",
       "      <td>34.2%~5.4%</td>\n",
       "      <td>37.1%~4.9%</td>\n",
       "      <td>36.8%~4.6%</td>\n",
       "      <td>35.0%~3.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>35.4%~9.9%</td>\n",
       "      <td>38.5%~6.3%</td>\n",
       "      <td>35.3%~5.2%</td>\n",
       "      <td>31.8%~4.6%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>31.6%~9.5%</td>\n",
       "      <td>32.3%~5.5%</td>\n",
       "      <td>32.8%~4.0%</td>\n",
       "      <td>33.2%~4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Net</th>\n",
       "      <td>35.3%~7.8%</td>\n",
       "      <td>29.6%~9.2%</td>\n",
       "      <td>31.8%~9.1%</td>\n",
       "      <td>34.2%~3.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>32.8%~9.0%</td>\n",
       "      <td>32.1%~6.4%</td>\n",
       "      <td>30.0%~3.9%</td>\n",
       "      <td>31.8%~5.8%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>30.0%~8.0%</td>\n",
       "      <td>32.0%~6.3%</td>\n",
       "      <td>33.2%~2.8%</td>\n",
       "      <td>34.6%~4.5%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0.8         0.6         0.4         0.2\n",
       "Nearest Neighbors 4  31.7%~7.5%  31.0%~7.3%  32.2%~4.4%  32.0%~5.0%\n",
       "Linear SVM           25.8%~8.0%  27.9%~6.3%  30.2%~4.1%  27.4%~3.4%\n",
       "Linear SVM MAGNN     34.2%~5.4%  37.1%~4.9%  36.8%~4.6%  35.0%~3.0%\n",
       "Decision Tree        35.4%~9.9%  38.5%~6.3%  35.3%~5.2%  31.8%~4.6%\n",
       "Random Forest        31.6%~9.5%  32.3%~5.5%  32.8%~4.0%  33.2%~4.0%\n",
       "Neural Net           35.3%~7.8%  29.6%~9.2%  31.8%~9.1%  34.2%~3.2%\n",
       "AdaBoost             32.8%~9.0%  32.1%~6.4%  30.0%~3.9%  31.8%~5.8%\n",
       "Naive Bayes          30.0%~8.0%  32.0%~6.3%  33.2%~2.8%  34.6%~4.5%"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tests_macro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "9890d0ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.8</th>\n",
       "      <th>0.6</th>\n",
       "      <th>0.4</th>\n",
       "      <th>0.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Nearest Neighbors 4</th>\n",
       "      <td>32.9%~7.1%</td>\n",
       "      <td>32.2%~7.1%</td>\n",
       "      <td>34.1%~4.3%</td>\n",
       "      <td>33.2%~5.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM</th>\n",
       "      <td>27.1%~8.2%</td>\n",
       "      <td>30.2%~4.1%</td>\n",
       "      <td>34.5%~4.1%</td>\n",
       "      <td>32.3%~2.5%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Linear SVM MAGNN</th>\n",
       "      <td>35.7%~5.1%</td>\n",
       "      <td>37.6%~4.8%</td>\n",
       "      <td>37.3%~4.4%</td>\n",
       "      <td>35.6%~3.1%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Decision Tree</th>\n",
       "      <td>37.1%~9.1%</td>\n",
       "      <td>39.5%~6.1%</td>\n",
       "      <td>36.4%~4.8%</td>\n",
       "      <td>33.5%~3.9%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest</th>\n",
       "      <td>32.9%~9.3%</td>\n",
       "      <td>34.4%~4.8%</td>\n",
       "      <td>35.5%~3.6%</td>\n",
       "      <td>35.5%~4.0%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Neural Net</th>\n",
       "      <td>40.0%~8.0%</td>\n",
       "      <td>35.1%~4.6%</td>\n",
       "      <td>35.4%~5.5%</td>\n",
       "      <td>35.9%~2.2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AdaBoost</th>\n",
       "      <td>33.6%~9.1%</td>\n",
       "      <td>32.9%~5.8%</td>\n",
       "      <td>30.7%~4.1%</td>\n",
       "      <td>35.9%~3.4%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Naive Bayes</th>\n",
       "      <td>32.1%~8.5%</td>\n",
       "      <td>32.0%~5.9%</td>\n",
       "      <td>33.7%~3.0%</td>\n",
       "      <td>35.1%~4.4%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            0.8         0.6         0.4         0.2\n",
       "Nearest Neighbors 4  32.9%~7.1%  32.2%~7.1%  34.1%~4.3%  33.2%~5.1%\n",
       "Linear SVM           27.1%~8.2%  30.2%~4.1%  34.5%~4.1%  32.3%~2.5%\n",
       "Linear SVM MAGNN     35.7%~5.1%  37.6%~4.8%  37.3%~4.4%  35.6%~3.1%\n",
       "Decision Tree        37.1%~9.1%  39.5%~6.1%  36.4%~4.8%  33.5%~3.9%\n",
       "Random Forest        32.9%~9.3%  34.4%~4.8%  35.5%~3.6%  35.5%~4.0%\n",
       "Neural Net           40.0%~8.0%  35.1%~4.6%  35.4%~5.5%  35.9%~2.2%\n",
       "AdaBoost             33.6%~9.1%  32.9%~5.8%  30.7%~4.1%  35.9%~3.4%\n",
       "Naive Bayes          32.1%~8.5%  32.0%~5.9%  33.7%~3.0%  35.1%~4.4%"
      ]
     },
     "execution_count": 263,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tests_micro"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
