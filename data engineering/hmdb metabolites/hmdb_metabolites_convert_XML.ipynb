{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convert HMDB XML export to pythonic format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests as req\n",
    "from lxml import etree as ET\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import json\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "\n",
    "import data_utils as du\n",
    "\n",
    "data_dir = du.find_data_dir('app')\n",
    "source = du.get_file_path(data_dir, 'HMDB metabolites', 'Raw xml', 'hmdb_metabolites.xml')\n",
    "\n",
    "hmdb_metabolites_secondary_accessions_file = du.get_file_path(data_dir, 'HMDB metabolites', 'Parsed pickle', 'hmdb_metabolites_secondary_accessions.p')\n",
    "hmdb_metabolites_direct_features_file = du.get_file_path(data_dir, 'HMDB metabolites', 'Parsed pickle', 'hmdb_metabolites_direct_features.p')\n",
    "hmdb_metabolites_synonyms_file = du.get_file_path(data_dir, 'HMDB metabolites', 'Parsed pickle', 'hmdb_metabolites_synonyms.p')\n",
    "hmdb_metabolites_taxonomy_file = du.get_file_path(data_dir, 'HMDB metabolites', 'Parsed pickle', 'hmdb_metabolites_taxonomy.p')\n",
    "hmdb_metabolites_biological_properties_file = du.get_file_path(data_dir, 'HMDB metabolites', 'Parsed pickle', 'hmdb_metabolites_biological_properties.p')\n",
    "hmdb_metabolites_physical_properties_file = du.get_file_path(data_dir, 'HMDB metabolites', 'Parsed pickle', 'hmdb_metabolites_physical_properties.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_features = ['accession', 'name']\n",
    "    \n",
    "direct_features = ['accession', 'name', 'description', 'chemical_formula', 'average_molecular_weight', \n",
    "                   'monisotopic_molecular_weight', 'iupac_name', 'traditional_iupac', \n",
    "                   'cas_registry_number', 'smiles', 'inchi', 'inchikey', 'state', 'synthesis_reference']\n",
    "\n",
    "direct_dict_features = ['taxonomy', 'biological_properties']\n",
    "\n",
    "taxonomy_list_names = ['alternative_parents', 'substituents', 'external_descriptors']\n",
    "\n",
    "indirect_list_features = []\n",
    "\n",
    "indirect_list_of_dicts_features = ['ontology', 'experimental_properties', 'predicted_properties', 'spectra', 'normal_concentrations', 'abnormal_concentrations', 'diseases', 'general_references', 'protein_associations']\n",
    "\n",
    "physical_properties_features = ['experimental_properties', 'predicted_properties']\n",
    "\n",
    "other_db_ids = ['kegg_id', 'foodb_id', 'chemspider_id', 'drugbank_id', 'pdb_id',\n",
    "                'chebi_id', 'pubchem_compound_id', 'biocyc_id', 'wikipedia_id',\n",
    "                'knapsack_id', 'phenol_explorer_compound_id', 'bigg_id', 'metlin_id',\n",
    "                'vmh_id', 'fbonto_id']\n",
    "\n",
    "unprocessed = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_child(elem, childname, namespace):\n",
    "    return elem.find(namespace+f'{childname}')\n",
    "\n",
    "def text_of_child(elem, childname, namespace):\n",
    "    return get_child(elem, childname, namespace).text\n",
    "\n",
    "def list_childnames(elem):\n",
    "    if len(elem) > 0:\n",
    "        return [child.text for child in elem]\n",
    "    else:\n",
    "        return []\n",
    "\n",
    "def create_dict_of_elem(elem, namespace):\n",
    "    elem_dict = {}\n",
    "    for child in elem:\n",
    "        tag = child.tag.replace(namespace, '')\n",
    "        if tag=='descendants' or tag=='references':\n",
    "            elem_dict[tag] = create_list_of_dicts(child, namespace)\n",
    "        elif tag=='synonyms':\n",
    "            elem_dict[tag] = list_childnames(child)\n",
    "        else:\n",
    "            elem_dict[tag] = child.text\n",
    "    return elem_dict\n",
    "\n",
    "def create_list_of_dicts(elem, namespace):\n",
    "    list_of_dicts = []\n",
    "    for instance_elem in elem:\n",
    "        list_of_dicts.append(create_dict_of_elem(instance_elem, namespace))\n",
    "    return list_of_dicts\n",
    "        \n",
    "def parse_metabolite(new_metabolite, namespace):   \n",
    "    new_dict = {}\n",
    "    \n",
    "    for feature in direct_features:\n",
    "        new_dict[feature] = text_of_child(new_metabolite, feature, namespace)\n",
    "        \n",
    "    for indirect_list_feature in indirect_list_features:\n",
    "        feature_elem = get_child(new_metabolite, indirect_list_feature, namespace)\n",
    "        new_dict[indirect_list_feature] = list_childnames(feature_elem)\n",
    "\n",
    "    for direct_dict_feature in direct_dict_features:\n",
    "        feature_elem = get_child(new_metabolite, direct_dict_feature, namespace)\n",
    "        feature_dict = create_dict_of_elem(feature_elem, namespace)\n",
    "        \n",
    "        if direct_dict_feature == 'taxonomy':\n",
    "            for taxonomy_list_name in taxonomy_list_names: \n",
    "                taxonomy_list_elem = get_child(feature_elem, taxonomy_list_name, namespace)\n",
    "                if taxonomy_list_elem:\n",
    "                    feature_dict[taxonomy_list_name] = list_childnames(taxonomy_list_elem)\n",
    "                else:\n",
    "                    feature_dict[taxonomy_list_name] = []\n",
    "\n",
    "        if direct_dict_feature == 'biological_properties':\n",
    "            feature_dict['cellular_locations'] = list_childnames(get_child(feature_elem, 'cellular_locations', namespace))\n",
    "            feature_dict['biospecimen_locations'] = list_childnames(get_child(feature_elem, 'biospecimen_locations', namespace))\n",
    "            feature_dict['tissue_locations'] = list_childnames(get_child(feature_elem, 'tissue_locations', namespace))\n",
    "            feature_dict['pathways'] = create_list_of_dicts(get_child(feature_elem, 'pathways', namespace), namespace)\n",
    "            \n",
    "        new_dict[direct_dict_feature] = feature_dict\n",
    "        \n",
    "    for indirect_list_of_dicts_feature in indirect_list_of_dicts_features:\n",
    "        feature_elem = get_child(new_metabolite, indirect_list_of_dicts_feature, namespace)\n",
    "        feature_list_of_dicts = create_list_of_dicts(feature_elem, namespace)\n",
    "        \n",
    "        new_dict[indirect_list_of_dicts_feature] = feature_list_of_dicts\n",
    "\n",
    "    for db_id in other_db_ids:\n",
    "        try:\n",
    "            new_dict[db_id] = text_of_child(new_metabolite, db_id, namespace)   \n",
    "        except:\n",
    "            new_dict[db_id] = None\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "def parse_taxonomy(new_metabolite, namespace):\n",
    "    new_dict = {}\n",
    "    \n",
    "    for ID_feature in ID_features:\n",
    "        new_dict[ID_feature] = text_of_child(new_metabolite, ID_feature, namespace)\n",
    "        \n",
    "    taxonomy_elem = get_child(new_metabolite, 'taxonomy', namespace)\n",
    "    taxonomy_dict = create_dict_of_elem(taxonomy_elem, namespace)\n",
    "\n",
    "    for taxonomy_list_name in taxonomy_list_names: \n",
    "        taxonomy_list_elem = get_child(taxonomy_elem, taxonomy_list_name, namespace)\n",
    "        if taxonomy_list_elem:\n",
    "            taxonomy_dict[taxonomy_list_name] = list_childnames(taxonomy_list_elem)\n",
    "        else:\n",
    "            taxonomy_dict[taxonomy_list_name] = []\n",
    "    \n",
    "    new_dict['taxonomy'] = taxonomy_dict\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def parse_biological_properties(new_metabolite, namespace):\n",
    "    new_dict = {}\n",
    "    \n",
    "    for ID_feature in ID_features:\n",
    "        new_dict[ID_feature] = text_of_child(new_metabolite, ID_feature, namespace)\n",
    "        \n",
    "    bio_prop_elem = get_child(new_metabolite, 'biological_properties', namespace)\n",
    "    bio_prop_dict = create_dict_of_elem(bio_prop_elem, namespace)\n",
    "\n",
    "    bio_prop_dict['cellular_locations'] = list_childnames(get_child(bio_prop_elem, 'cellular_locations', namespace))\n",
    "    bio_prop_dict['biospecimen_locations'] = list_childnames(get_child(bio_prop_elem, 'biospecimen_locations', namespace))\n",
    "    bio_prop_dict['tissue_locations'] = list_childnames(get_child(bio_prop_elem, 'tissue_locations', namespace))\n",
    "    bio_prop_dict['pathways'] = create_list_of_dicts(get_child(bio_prop_elem, 'pathways', namespace), namespace)\n",
    "\n",
    "    new_dict['biological_properties'] = bio_prop_dict\n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def parse_physical_properties(new_metabolite, namespace):\n",
    "    new_dict = {}\n",
    "    \n",
    "    for ID_feature in ID_features:\n",
    "        new_dict[ID_feature] = text_of_child(new_metabolite, ID_feature, namespace)\n",
    "        \n",
    "    for physical_property_feature in physical_properties_features:\n",
    "        feature_elem = get_child(new_metabolite, physical_property_feature, namespace)\n",
    "        feature_list_of_dicts = create_list_of_dicts(feature_elem, namespace)\n",
    "        \n",
    "        new_dict[physical_property_feature] = feature_list_of_dicts        \n",
    "    \n",
    "    return new_dict\n",
    "\n",
    "def test_ontology(new_metabolite, namespace):\n",
    "    ontology_elem = new_metabolite.find(namespace+f'ontology')\n",
    "    feature_list_of_dicts = create_list_of_dicts(ontology_elem, namespace)\n",
    "    for dict in feature_list_of_dicts:\n",
    "        print(json.dumps(dict,indent=1))\n",
    "\n",
    "def test_parse(new_metabolite, namespace):\n",
    "    feature_elem = new_metabolite.find(namespace+f'gene_properties')\n",
    "    for child in new_metabolite:\n",
    "        print(child.tag.replace(namespace, ''), ':', child.text)\n",
    "\n",
    "def parse_index(new_metabolite, namespace, start_line, end_line):\n",
    "    new_dict = {}\n",
    "    \n",
    "    for ID_feature in ID_features:\n",
    "        new_dict[ID_feature] = text_of_child(new_metabolite, ID_feature, namespace)\n",
    "    \n",
    "    new_dict['start_line'] = start_line\n",
    "    new_dict['end_line'] = end_line\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "def parse_direct_features(new_metabolite, namespace):\n",
    "    new_dict = {}\n",
    "    \n",
    "    for feature in direct_features:\n",
    "        new_dict[feature] = text_of_child(new_metabolite, feature, namespace)  \n",
    "\n",
    "    for db_id in other_db_ids:\n",
    "        try:\n",
    "            new_dict[db_id] = text_of_child(new_metabolite, db_id, namespace) \n",
    "        except:\n",
    "            new_dict[db_id] = None\n",
    "\n",
    "    return new_dict\n",
    "\n",
    "def parse_synonyms(new_metabolite, namespace):    \n",
    "    synonyms = new_metabolite.find(namespace+f'synonyms')\n",
    "    synonyms_list = []\n",
    "    \n",
    "    for synonym in synonyms:\n",
    "        synonyms_list.append(synonym.text)\n",
    "    \n",
    "    new_dict = {'name': new_metabolite.find(namespace+f'name').text,\n",
    "                'accession': new_metabolite.find(namespace+f'accession').text, \n",
    "                'synonyms': synonyms_list}\n",
    "    return new_dict\n",
    "\n",
    "def parse_secondary_accesions(new_metabolite, namespace):\n",
    "    secondary_accessions = list_childnames(get_child(new_metabolite, 'secondary_accessions', namespace))\n",
    "    new_dict = {'accession': new_metabolite.find(namespace+f'accession').text, \n",
    "                'secondary_accessions': secondary_accessions}\n",
    "    return new_dict\n",
    "\n",
    "def parse_hmdb_xml(filename, parse_function):\n",
    "    metabolite_dicts = [{}]*114222\n",
    "    context = ET.iterparse(filename, events=(\"start\",\"end\"))\n",
    "    namespace = '{http://www.hmdb.ca}'\n",
    "    metabolite = namespace+'metabolite'\n",
    "    hmdb = namespace+'hmdb'\n",
    "    \n",
    "    metabolite_counter=0\n",
    "    t0 = time.time()\n",
    "    \n",
    "    for event, elem in context:\n",
    "        if event==\"start\":\n",
    "            if elem.tag==metabolite:\n",
    "                new_metabolite = elem\n",
    "            elif elem.tag==hmdb:\n",
    "                continue\n",
    "        elif event==\"end\":\n",
    "            if elem.tag==metabolite:\n",
    "                metabolite_dicts[metabolite_counter] = parse_function(elem, namespace)\n",
    "                metabolite_counter+= 1\n",
    "                if metabolite_counter % 1000==0 and metabolite_counter>0:\n",
    "                    clear_output(wait=True)\n",
    "                    t1 = time.time()\n",
    "                    duration = float(t1-t0)\n",
    "                    print(f'Finished {metabolite_counter} in {duration:.0f}s')\n",
    "                elem.clear()\n",
    "                \n",
    "    return metabolite_dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse raw XML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Secondary accessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 1000 in 8s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-054c0b8716d9>\u001b[0m in \u001b[0;36mparse_hmdb_xml\u001b[0;34m(filename, parse_function)\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mevent\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;34m\"start\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtag\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0mmetabolite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hmdb_metabolites_secondary_accessions = parse_hmdb_xml(str(source), parse_secondary_accesions)\n",
    "du.dump_in_pickle(hmdb_metabolites_secondary_accessions_file, hmdb_metabolites_secondary_accessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Direct features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 114000 in 225s\n",
      "CPU times: user 3min 43s, sys: 3.04 s, total: 3min 46s\n",
      "Wall time: 3min 46s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hmdb_metabolites_direct_features = parse_hmdb_xml(str(source), parse_direct_features)\n",
    "du.dump_in_pickle(hmdb_metabolites_direct_features_file, hmdb_metabolites_direct_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Synonyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 114000 in 183s\n",
      "CPU times: user 3min 2s, sys: 1.18 s, total: 3min 3s\n",
      "Wall time: 3min 3s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hmdb_metabolites_synonyms = parse_hmdb_xml(str(source), parse_synonyms)\n",
    "du.dump_in_pickle(hmdb_metabolites_synonyms_file, hmdb_metabolites_synonyms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taxonomy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 114000 in 163s\n",
      "CPU times: user 2min 43s, sys: 1.83 s, total: 2min 45s\n",
      "Wall time: 2min 44s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hmdb_metabolites_taxonomy = parse_hmdb_xml(str(source), parse_taxonomy)\n",
    "du.dump_in_pickle(hmdb_metabolites_taxonomy_file, hmdb_metabolites_taxonomy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Biological properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 s, sys: 230 ms, total: 1.95 s\n",
      "Wall time: 1.95 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hmdb_metabolites_biological_properties = parse_hmdb_xml(str(source), parse_biological_properties)\n",
    "du.dump_in_pickle(hmdb_metabolites_biological_properties_file, hmdb_metabolites_biological_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Physical properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 114000 in 186s\n",
      "CPU times: user 3min 9s, sys: 2.97 s, total: 3min 12s\n",
      "Wall time: 3min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "hmdb_metabolites_physical_properties = parse_hmdb_xml(str(source), parse_physical_properties)\n",
    "du.dump_in_pickle(hmdb_metabolites_physical_properties_file, hmdb_metabolites_physical_properties)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read from pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hmdb_metabolites_direct_features = du.read_from_pickle(hmdb_metabolites_direct_features_file)\n",
    "hmdb_metabolites_synonyms = du.read_from_pickle(hmdb_metabolites_synonyms_file)\n",
    "hmdb_metabolites_taxonomy = du.read_from_pickle(hmdb_metabolites_taxonomy_file)\n",
    "hmdb_metabolites_biological_properties = du.read_from_pickle(hmdb_metabolites_biological_properties_file)\n",
    "hmdb_metabolites_physical_properties = du.read_from_pickle(hmdb_metabolites_physical_properties_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accession': 'HMDB0000001',\n",
       " 'name': '1-Methylhistidine',\n",
       " 'description': \"1-Methylhistidine, also known as 1-MHis, belongs to the class of organic compounds known as histidine and derivatives. Histidine and derivatives are compounds containing cysteine or a derivative thereof resulting from a reaction of cysteine at the amino group or the carboxy group, or from the replacement of any hydrogen of glycine by a heteroatom. 1-Methylhistidine is derived mainly from the anserine of dietary flesh sources, especially poultry. The enzyme, carnosinase, splits anserine into beta-alanine and 1-MHis. High levels of 1-MHis tend to inhibit the enzyme carnosinase and increase anserine levels. Conversely, genetic variants with deficient carnosinase activity in plasma show increased 1-MHis excretions when they consume a high meat diet. Reduced serum carnosinase activity is also found in patients with Parkinson's disease and multiple sclerosis and patients following a cerebrovascular accident. Vitamin E deficiency can lead to 1-methylhistidinuria from increased oxidative effects in skeletal muscle. 1-Methylhistidine is a biomarker for the consumption of meat, especially red meat.\",\n",
       " 'chemical_formula': 'C7H11N3O2',\n",
       " 'average_molecular_weight': '169.1811',\n",
       " 'monisotopic_molecular_weight': '169.085126611',\n",
       " 'iupac_name': '(2S)-2-amino-3-(1-methyl-1H-imidazol-4-yl)propanoic acid',\n",
       " 'traditional_iupac': '1 methylhistidine',\n",
       " 'cas_registry_number': '332-80-9',\n",
       " 'smiles': 'CN1C=NC(C[C@H](N)C(O)=O)=C1',\n",
       " 'inchi': 'InChI=1S/C7H11N3O2/c1-10-3-5(9-4-10)2-6(8)7(11)12/h3-4,6H,2,8H2,1H3,(H,11,12)/t6-/m0/s1',\n",
       " 'inchikey': 'BRMWTNUJHUMWMS-LURJTMIESA-N',\n",
       " 'state': 'Solid',\n",
       " 'synthesis_reference': 'Jain, Rahul; Cohen, Louis A. Regiospecific alkylation of histidine and histamine at N-1 (t).Tetrahedron  (1996),  52(15),  5363-70.',\n",
       " 'kegg_id': 'C01152',\n",
       " 'foodb_id': 'FDB093588',\n",
       " 'chemspider_id': '83153',\n",
       " 'drugbank_id': 'DB04151',\n",
       " 'pdb_id': None,\n",
       " 'chebi_id': '50599',\n",
       " 'pubchem_compound_id': '92105',\n",
       " 'biocyc_id': None,\n",
       " 'wikipedia_id': 'Methylhistidine',\n",
       " 'knapsack_id': None,\n",
       " 'phenol_explorer_compound_id': None,\n",
       " 'bigg_id': None,\n",
       " 'metlin_id': '3741',\n",
       " 'vmh_id': None,\n",
       " 'fbonto_id': None}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hmdb_metabolites_direct_features[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
